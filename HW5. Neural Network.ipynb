{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw05_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qp0H_zUQuu_"
      },
      "source": [
        "# Нейронные сети\n",
        "__Суммарное количество баллов: 10__\n",
        "\n",
        "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
        "\n",
        "__Тема письма: `[ML][HW05] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
        "\n",
        "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ezVRf3QuvA"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from sklearn.datasets import make_blobs, make_moons\n",
        "from typing import List, NoReturn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfDPH_LQuvF"
      },
      "source": [
        "### Задание 1 (3 балла)\n",
        "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
        "\n",
        "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
        "\n",
        "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
        "\n",
        "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
        "\n",
        "\n",
        "#### Методы\n",
        "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
        "\n",
        "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
        "\n",
        "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFLlHqaYbgC"
      },
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Абстрактный класс. Его менять не нужно.\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def backward(self, d):\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def update(self, alpha):\n",
        "        pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYS2gE4PYepZ"
      },
      "source": [
        "class Linear(Module):\n",
        "    \"\"\"\n",
        "    Линейный полносвязный слой.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_features : int\n",
        "            Размер входа.\n",
        "        out_features : int \n",
        "            Размер выхода.\n",
        "    \n",
        "        Notes\n",
        "        -----\n",
        "        W и b инициализируются случайно.\n",
        "        \"\"\"\n",
        "        self.__in_features = in_features\n",
        "        self.__out_features = out_features\n",
        "        self.__W = np.random.uniform(0, 0.01, size=(self.__in_features, self.__out_features))\n",
        "        self.__bias = np.random.uniform(0, 0.01, size=self.__out_features)\n",
        "        \n",
        "    \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Wx + b.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "            То есть, либо x вектор с in_features элементов,\n",
        "            либо матрица размерности (batch_size, in_features).\n",
        "    \n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя.\n",
        "            Либо вектор с out_features элементами,\n",
        "            либо матрица размерности (batch_size, out_features)\n",
        "\n",
        "        \"\"\"\n",
        "        self.__x = x\n",
        "        return x @ self.__W + self.__bias\n",
        "    \n",
        "    def backward(self, d: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        self.__grad = d @ self.__W.T\n",
        "        self.__W_grad = self.__x.T @ d\n",
        "        self.__bias_grad = d.sum(axis=0)\n",
        "\n",
        "        return self.__grad\n",
        "        \n",
        "    def update(self, alpha: float) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обновляет W и b с заданной скоростью обучения.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha : float\n",
        "            Скорость обучения.\n",
        "        \"\"\"\n",
        "        self.__W -= alpha * self.__W_grad\n",
        "        self.__bias -= alpha * self.__bias_grad"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hkbnD1QuvG"
      },
      "source": [
        "class ReLU(Module):\n",
        "    \"\"\"\n",
        "    Слой, соответствующий функции активации ReLU.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = max(0, x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "    \n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        self.__x = x\n",
        "\n",
        "        return np.maximum(0, self.__x)\n",
        "        \n",
        "    def backward(self, d) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        grad = self.__x > 0\n",
        "        return d * grad\n",
        "        \n",
        "        \n",
        "class Softmax(Module):\n",
        "    \"\"\"\n",
        "    Слой, соответствующий функции активации Softmax.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Softmax(x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "    \n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        self.__x = x\n",
        "\n",
        "        return self.__x\n",
        "        \n",
        "    def backward(self, d = None) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        exp = np.exp(self.__x)\n",
        "        softmax_val = exp / exp.sum(axis=-1, keepdims=True)\n",
        "        return -d + softmax_val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_ip_h8QuvJ"
      },
      "source": [
        "### Задание 2 (2 балла)\n",
        "Теперь сделаем саму нейронную сеть.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
        "\n",
        "#### Параметры конструктора\n",
        "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
        "\n",
        "`epochs` - количество эпох обучения\n",
        "\n",
        "`alpha` - скорость обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_JFCizKQuvK"
      },
      "source": [
        "class MLPClassifier:\n",
        "    def __init__(self, modules: List[Module], epochs: int = 40, alpha: float = 0.01):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        modules : List[Module]\n",
        "            Cписок, состоящий из ранее реализованных модулей и \n",
        "            описывающий слои нейронной сети. \n",
        "            В конец необходимо добавить Softmax.\n",
        "        epochs : int\n",
        "            Количество эпох обученияю\n",
        "        alpha : float\n",
        "            Cкорость обучения.\n",
        "        \"\"\"\n",
        "        self.__modules = modules\n",
        "        self.__modules.append(Softmax())\n",
        "        \n",
        "        self.__epochs = epochs\n",
        "        self.__alpha = alpha\n",
        "\n",
        "\n",
        "    def __loss(self, x, y):\n",
        "        return -x[range(x.shape[0]), y] + np.log(np.exp(x).sum(axis = 1))\n",
        "\n",
        "    \n",
        "    def __grad_loss(self, x, y):\n",
        "        n = x.shape[0]\n",
        "        matrix = np.zeros(shape=x.shape)\n",
        "        matrix[range(n), y] = 1\n",
        "\n",
        "        return matrix\n",
        "\n",
        "            \n",
        "    def fit(self, X: np.ndarray, y: np.ndarray, batch_size=32) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обучает нейронную сеть заданное число эпох. \n",
        "        В каждой эпохе необходимо использовать cross-entropy loss для обучения, \n",
        "        а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для обучения.\n",
        "        y : np.ndarray\n",
        "            Вектор меток классов для данных.\n",
        "        batch_size : int\n",
        "            Размер батча.\n",
        "        \"\"\"\n",
        "        n_batches = X.shape[0] // batch_size + 1\n",
        "        batches = np.array_split(X, n_batches)\n",
        "        y_batches = np.array_split(y, n_batches)\n",
        "\n",
        "        softmax = Softmax()\n",
        "\n",
        "        for i in range(self.__epochs):\n",
        "            for j in range(n_batches):\n",
        "                output = batches[j]\n",
        "\n",
        "                for layer in self.__modules:\n",
        "                    output = layer.forward(output)\n",
        "\n",
        "                loss = self.__loss(output, y_batches[j])\n",
        "                grad = self.__grad_loss(output, y_batches[j])\n",
        "\n",
        "                for layer in self.__modules[::-1]:\n",
        "                    grad = layer.backward(grad)\n",
        "                    layer.update(self.__alpha)\n",
        "\n",
        "        \n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказывает вероятности классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Предсказанные вероятности классов для всех элементов X.\n",
        "            Размерность (X.shape[0], n_classes)\n",
        "        \n",
        "        \"\"\"\n",
        "        output = X\n",
        "\n",
        "        for layer in self.__modules:\n",
        "            output = layer.forward(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "        \n",
        "    def predict(self, X) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказывает метки классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Вектор предсказанных классов\n",
        "        \n",
        "        \"\"\"\n",
        "        p = self.predict_proba(X)\n",
        "        return np.argmax(p, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onDymYQXQuvN"
      },
      "source": [
        "p = MLPClassifier([\n",
        "    Linear(4, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 2)\n",
        "])\n",
        "\n",
        "X = np.random.randn(50, 4)\n",
        "y = np.array([(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X])\n",
        "p.fit(X, y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C1EIsDqQuvQ"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
        "\n",
        "#### Оценка\n",
        "Accuracy на первом датасете больше 0.85 - +1 балл\n",
        "\n",
        "Accuracy на втором датасете больше 0.85 - +1 балл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UAgXTcQuvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d08a4f-fcac-4247-a96d-b2052f0a9330"
      },
      "source": [
        "X, y = make_moons(400, noise=0.075)\n",
        "X_test, y_test = make_moons(400, noise=0.075)\n",
        "\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([Linear(2, 2)], epochs=100)\n",
        "\n",
        "    p.fit(X, y)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMDJM4qFQuvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c50cce-1212-49e4-8a9f-4d3548735c8f"
      },
      "source": [
        "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([Linear(2, 3)], epochs=100)\n",
        "\n",
        "    p.fit(X, y)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.9675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPbVTFnMQuvW"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0mJLu-QuvX"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUC_QqpAQuva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75d3843-ceae-4899-c703-336eca015f80"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "t = transforms.ToTensor()\n",
        "\n",
        "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
        "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
        "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmpjcFfQuvd"
      },
      "source": [
        "### Задание 4 (3 балла)\n",
        "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
        "\n",
        "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
        "\n",
        "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
        "\n",
        "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sRmTKwKQuve"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.__layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(128 * 8 * 8, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
        "        return self.__layers(x)\n",
        "        \n",
        "def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n",
        "    \"\"\"\n",
        "    Cчитает cross-entropy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : torch.Tensor\n",
        "        Данные для обучения.\n",
        "    y : torch.Tensor\n",
        "        Метки классов.\n",
        "    model : Model\n",
        "        Модель, которую будем обучать.\n",
        "\n",
        "    \"\"\"\n",
        "    y_pred = model(X)\n",
        "    loss = F.cross_entropy(y_pred, y)\n",
        "    return loss"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsLmkUqQuvh"
      },
      "source": [
        "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5G8iMCeQuvh"
      },
      "source": [
        "def train(model, epochs=100):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for i in range(epochs):\n",
        "        #Train\n",
        "        loss_mean = 0\n",
        "        elements = 0\n",
        "        for X, y in iter(train_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        train_losses.append(loss_mean / elements)\n",
        "        #Test\n",
        "        loss_mean = 0 \n",
        "        elements = 0\n",
        "        for X, y in iter(test_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        test_losses.append(loss_mean / elements)\n",
        "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
        "    return train_losses, test_losses"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmD9eWJOQuvl",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e950fce3-b38c-467b-a14d-38bb64a27288"
      },
      "source": [
        "model = Model().to(device)\n",
        "train_l, test_l = train(model, epochs=10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Train loss 1.98812784614563 | Test loss 1.6594544828414917\n",
            "Epoch 1 | Train loss 1.505906873550415 | Test loss 1.356641018676758\n",
            "Epoch 2 | Train loss 1.2786432052612304 | Test loss 1.263756844329834\n",
            "Epoch 3 | Train loss 1.1238055960845947 | Test loss 1.0640560024261474\n",
            "Epoch 4 | Train loss 0.9708264465904236 | Test loss 0.9743073011398315\n",
            "Epoch 5 | Train loss 0.8490566003036499 | Test loss 0.8854419298171997\n",
            "Epoch 6 | Train loss 0.7341310449790954 | Test loss 0.8866515481948852\n",
            "Epoch 7 | Train loss 0.6411129385185241 | Test loss 0.8330265441894531\n",
            "Epoch 8 | Train loss 0.5243961050796508 | Test loss 0.8254875788688659\n",
            "Epoch 9 | Train loss 0.4142931729888916 | Test loss 0.8431470276832581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJNAuHjNQuvn"
      },
      "source": [
        "Построим график функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6OEGqriQuvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "3be9f291-d46b-40c6-88e2-e9d50186a357"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
        "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miUxg0bDQuvs"
      },
      "source": [
        "И, наконец, посчитаем метрики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSOJFI8Quvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c26ade-849b-4881-a3d5-9203aad3b887"
      },
      "source": [
        "true_positive = np.zeros(10)\n",
        "true_negative = np.zeros(10)\n",
        "false_positive = np.zeros(10)\n",
        "false_negative = np.zeros(10)\n",
        "accuracy = 0\n",
        "ctn = 0\n",
        "for X, y in iter(test_loader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X).max(dim=1)[1]\n",
        "    for i in range(10):\n",
        "        for pred, real in zip(y_pred, y):\n",
        "            if real == i:\n",
        "                if pred == real:\n",
        "                    true_positive[i] += 1\n",
        "                else:\n",
        "                    false_negative[i] += 1\n",
        "            else:\n",
        "                if pred == i:\n",
        "                    false_positive[i] += 1\n",
        "                else:\n",
        "                    true_negative[i] += 1\n",
        "            \n",
        "    accuracy += torch.sum(y_pred == y).item()\n",
        "    ctn += len(y)\n",
        "print(\"Overall accuracy\", accuracy / ctn)\n",
        "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
        "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
        "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
        "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy 0.7277\n",
            "Precision [0.67201283 0.84023669 0.66309013 0.55897981 0.66731329 0.68944099\n",
            " 0.76431925 0.75718258 0.88380282 0.78916828]\n",
            "Recall [0.838 0.852 0.618 0.526 0.688 0.555 0.814 0.817 0.753 0.816]\n",
            "Mean Precision 0.7285546657229957\n",
            "Mean Recall 0.7277\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}